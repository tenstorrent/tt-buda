import pybuda
import cv2
import torch.nn.init as init
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import os, sys
from pybuda.verify.backend import verify_module
from pybuda import VerifyConfig
from pybuda.verify.config import TestKind


def test_rcnn_pytorch(test_device):

    # Load Alexnet Model
    model = torchvision.models.alexnet(pretrained=True)
    num_classes = 2
    num_features = model.classifier[6].in_features

    # Create class specific linear SVMs [Refer Section 2 in paper]
    svm_layer = nn.Linear(num_features, num_classes)

    # Replacing the Alexnet's ImageNet specific 1000-way classification layer with a randomly initialized (N + 1)-way classification layer(where N is the number of object classes, plus 1 for background)
    # [Refer Section 2.3.Domain-specific fine-tuning in Paper]
    init.normal_(svm_layer.weight, mean=0, std=0.01)
    init.constant_(svm_layer.bias, 0)
    model.classifier[6] = svm_layer

    model.eval()

    # Cancel gradient tracking
    for param in model.parameters():
        param.requires_grad = False

    # Image
    img = cv2.imread("pybuda/test/model_demos/utils/cnn/pytorch/images/car.jpg")

    transform = transforms.Compose(
        [
            transforms.ToPILImage(),
            transforms.Resize((227, 227)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )

    # Selective search - A separate tool for generating proposals(potential regions that might contain objects) which can be fed to actual model
    # As it is a pre-processing step,it is implemented on cpu
    gs = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    gs.setBaseImage(img)
    gs.switchToSelectiveSearchFast()
    rects = gs.process()
    rects[:, 2] += rects[:, 0]
    rects[:, 3] += rects[:, 1]
    print("Suggested number of proposals: %d" % len(rects))

    # PyBuda configuration parameters
    compiler_cfg = pybuda.config._get_global_compiler_config()
    compiler_cfg.balancer_policy = "Ribbon"
    compiler_cfg.default_df_override = pybuda._C.Float16_b
    os.environ["PYBUDA_RIBBON2"] = "1"

    # Pybuda model
    tt_model = pybuda.PyTorchModule("rcnn", model)

    # Proposals generated by selective search were fed to a model in a loop manner to compute features.
    # [Refer line No.151 in https://github.com/object-detection-algorithm/R-CNN/blob/master/py/car_detector.py]
    for rect in rects:

        xmin, ymin, xmax, ymax = rect
        rect_img = img[ymin:ymax, xmin:xmax]

        rect_transform = transform(rect_img)
        inputs = rect_transform.unsqueeze(0)

        verify_module(
            tt_model,
            input_shapes=[inputs.shape],
            inputs=[(inputs)],
            verify_cfg=VerifyConfig(
                arch=test_device.arch,
                devtype=test_device.devtype,
                devmode=test_device.devmode,
                test_kind=TestKind.INFERENCE,
            ),
        )

        break  # As generated proposals will be around 2000, halt inference after getting result from single proposal.


# Paper - https://arxiv.org/abs/1311.2524
# Repo - https://github.com/object-detection-algorithm/R-CNN
