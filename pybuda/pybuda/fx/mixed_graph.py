# SPDX-FileCopyrightText: Â© 2024 Tenstorrent AI ULC

# SPDX-License-Identifier: Apache-2.0

#
# Mixed graph contains a pybuda graph, and one or more FX graphs that will be executed on the CPU. It is 
# generated by capturing a FX graph from pt2. Unsupported ops, or arguments will be dropped down to CPU.
#

from typing import Dict, List, Tuple, Set
from collections import defaultdict
import os
import copy

import torch
from loguru import logger

import pybuda
from pybuda.fx.nodes import torch_constant_ops, call_function_is_nop, call_function_is_reshape
from pybuda.fx.schedule import Schedule
from pybuda.fx.graph_utils import reduce_graph, get_output_node, append_to_output, move_output_to_end, remove_output_index, graph_lint, is_nop_graph, is_constant_graph, has_output, graph_to_device
from pybuda.fx.trace import IOTracer
from pybuda._C.torch_device import unique_id

class MixedGraph:
    def __init__(self, module_name: str):
        self.graph = pybuda._C.graph.Graph(module_name)
        self.inputs_per_subgraph : Dict[int, List[int]] = {}
        self.outputs_per_subgraph : Dict[int, List[int]] = {}

        # Original graph nodes, ordered before the filtering
        self.input_nodes_per_subgraph : Dict[int, List[torch.fx.Node]] = {}
        self.output_nodes_per_subgraph : Dict[int, List[torch.fx.Node]] = {}

        self.fallback_graphs_per_subgraph: Dict[int, List[torch.fx.Graph]] = {}
        self.mappings_per_subgraph: Dict[int, Dict[str, Dict[torch.fx.Node, torch.fx.Node]]] = {}
        self.device_graphs_per_subgraph: Dict[int, List[torch.fx.Graph]] = {}
        
        # A bit hacky - but there's no compiler-level config for log level at the moment
        log_env = 'LOGURU_LEVEL'
        self.log_trace = log_env in os.environ and os.environ[log_env] == "TRACE"

    @classmethod
    def get_program_subgraph_id(cls, subgraph_idx: int, program_idx: int) -> int:
        # encode in one number, maybe break it up later
        assert program_idx < 100, "Too many programs in a single subgraph"
        return subgraph_idx * 100 + program_idx

    def capture_sample_inputs(self, inputs: List[torch.Tensor], subgraph_id: int):
        self.inputs_per_subgraph[subgraph_id] = [unique_id(t) for t in inputs]

    def capture_sample_outputs(self, outputs: List[torch.Tensor], subgraph_id: int):
        self.outputs_per_subgraph[subgraph_id] = [unique_id(t) for t in outputs]

    def get_subgraph_input(self, subgraph_id: int, input_index: int) -> int:
        return self.inputs_per_subgraph[subgraph_id][input_index]

    def get_output_index(self, uid) -> Tuple[int, int]:
        # Return the subgraph index and output index for the given uid
        for idx in self.outputs_per_subgraph:
            if uid in self.outputs_per_subgraph[idx]:
                return idx, self.outputs_per_subgraph[idx].index(uid)

        assert False, "Output not found"

    def filter_unsupported_nodes(self, device_graph: torch.fx.Graph, unsupported_ops: Set[torch.fx.Node], unsupported_outputs: Set[torch.fx.Node], subgraph_id: int):
        # Move unsupported ops to CPU

        # First, we'll copy all unsupported ops to a new FX graph. For each node that gets its input
        # from a supported op, we'll create a new input in the fallback graph, and output in the original graph.
        # We'll then record that mapping.

        # Mapping of input node on one graph, and node that drives the output on the other graph that should feed this input
        new_io_mapping : Dict[torch.fx.Node, torch.fx.Node] = {}

        # Placeholders that are copied into the new graph
        placeholder_map : Dict[torch.fx.Node, torch.fx.Node] = {}

        # Mapping of copied nodes
        copied_node_mapping : Dict[torch.fx.Node, torch.fx.Node] = {}

        # Mapping of outputs that got moved out of main graph into fallback, to fallback's output
        moved_output_mapping : Dict[torch.fx.Node, torch.fx.Node] = {}

        # List of inputs/outputs to create in the original graph, once we're done traversing and it's safe to modify
        scheduled_new_outputs : List[Tuple[torch.fx.Node, torch.fx.Node]] = [] # Tuple - source in original graph, dest in new graph
        scheduled_new_inputs : List[Tuple[torch.fx.Node, torch.fx.Node, torch.fx.Node]] = [] # Tuple - dest in original graph, source in original graph, source in new graph
        
        logger.trace("Initial graph:")
        if self.log_trace:
            device_graph.print_tabular()

        fallback_graph = torch.fx.Graph()

        if subgraph_id not in self.input_nodes_per_subgraph:
            self.input_nodes_per_subgraph[subgraph_id] = []

        if subgraph_id not in self.output_nodes_per_subgraph:
            self.output_nodes_per_subgraph[subgraph_id] = []
        
        output_node = get_output_node(device_graph)
        if output_node is None:
            self.device_graphs_per_subgraph[subgraph_id] = [fallback_graph]
            self.fallback_graphs_per_subgraph[subgraph_id] = []
            self.mappings_per_subgraph[subgraph_id] = {
                "new_io_mapping": new_io_mapping,
                "placeholder_map": placeholder_map,
                "copied_node_mapping": copied_node_mapping,
                "moved_output_mapping": moved_output_mapping
            }
            return [fallback_graph] # No outputs, nothing to do

        if is_constant_graph(device_graph):
            graph_to_device(device_graph, 'cpu')
            self.device_graphs_per_subgraph[subgraph_id] = [fallback_graph]
            self.fallback_graphs_per_subgraph[subgraph_id] = [device_graph]
            self.mappings_per_subgraph[subgraph_id] = {
                "new_io_mapping": new_io_mapping,
                "placeholder_map": placeholder_map,
                "copied_node_mapping": copied_node_mapping,
                "moved_output_mapping": moved_output_mapping
            }

            # Record outputs
            for arg in output_node.args[0]:
                self.output_nodes_per_subgraph[subgraph_id].append(arg)
                
            return [fallback_graph]


        # Some of the unsupported nodes will have nop arguments, which we want to copy over as well. Let's find those first.
        to_copy_ops = unsupported_ops.copy()
        to_copy_ops.update(unsupported_outputs)
        for node in device_graph.nodes:
                
            # While traversing, record original inputs/outputs
            if node.op == "placeholder":
                self.input_nodes_per_subgraph[subgraph_id].append(node)
                continue

            if node.op == "output":
                for arg in node.args[0]:
                    self.output_nodes_per_subgraph[subgraph_id].append(arg)
                continue

            if node not in unsupported_ops and node not in unsupported_outputs:
                continue
            
            for arg in node.all_input_nodes:
                if arg.op != "call_function":
                    continue
                
                op_name = arg.target.__name__
                if call_function_is_nop(arg):
                    to_copy_ops.add(arg)

            # If any of the users of unsupported ops are reshapes, they are easier to run on CPU anyway
            for user in node.users:
                if user.op == "call_function" and call_function_is_reshape(user):
                    to_copy_ops.add(user)
                    unsupported_ops.add(user)

        logger.trace(f"To copy/move to CPU: ", to_copy_ops)

        # Now go through and copy the nodes that need copying
        for node in device_graph.nodes:

            # If the output is driven by an unsupported op, then we need to move it over to the new graph
            if node.op == "output":
                assert len(node.args) == 1
                for driving_node in node.args[0]:
                    if driving_node in unsupported_ops or driving_node in unsupported_outputs:
                        logger.trace(f"Moving output: {driving_node} {hex(id(driving_node))}, to copied node: {hex(id(copied_node_mapping[driving_node]))}")
                        
                        # Add to fallback graph
                        append_to_output(fallback_graph, copied_node_mapping[driving_node])
                        moved_output_mapping[driving_node] = copied_node_mapping[driving_node]
                        
                continue

            # If the op is supported, but has an argument that's unsupported, then we need to create an output on fallback graph to get
            # the value, and a placeholder in the original graph, and map them 
            if node not in to_copy_ops:
                if not isinstance(node, torch.fx.Node):
                    continue
                for arg in node.all_input_nodes:
                    if arg not in unsupported_ops:
                        continue
                    
                    # Check if we already have this input scheduled
                    already_scheduled = False
                    for _, n, _ in scheduled_new_inputs:
                        if n == arg:
                            already_scheduled = True
                            break

                    if already_scheduled:
                        continue
                    
                    # We should've already made a copy of this, so it's safe to get it from copied_node_mapping
                    new_node = copied_node_mapping[arg]
                    append_to_output(fallback_graph, new_node)
                    scheduled_new_inputs.append((node, arg, new_node))

                continue

            if node not in to_copy_ops:
                continue

            # Figure out which of these need to be new inputs, and also create the map for copying
            arg_map : Dict[torch.fx.Node, torch.fx.Node] = {}

            def device_kwarg_to_cpu(node: torch.fx.Node):
                # If the node is a device kwarg, then we need to move it to CPU
                if 'device' in node.kwargs:
                    new_kwargs = node.kwargs.copy()
                    new_kwargs['device'] = 'cpu'
                    node.kwargs = new_kwargs

            for arg in node.all_input_nodes:
            
                if arg in to_copy_ops:
                    # We should've already made a copy of this
                    assert arg in copied_node_mapping, f"Node {arg} not copied, but it's an argument to {node} and in 'to copy ops'"
                    arg_map[arg] = copied_node_mapping[arg]
                    continue
                
                if arg.op == "call_function":
                    op_name = arg.target.__name__

                    # If the function is a constant, copy it over, no sense it evaluating it on device and then copying
                    #if op_name in torch_constant_ops or op_name == "getitem":
                    if op_name in torch_constant_ops:
                        logger.trace(f"Copying constant op to fallback graph: {arg}")
                        new_node = fallback_graph.node_copy(arg, lambda x: x) # there should be no node args to copy in a constant op
                        copied_node_mapping[arg] = new_node
                        arg_map[arg] = new_node
                        device_kwarg_to_cpu(copied_node_mapping[arg])
                        continue

                    # Supported op, calculated on device. We need to create inputs and outputs, unless it's already an output
                    already_output = arg in self.output_nodes_per_subgraph[subgraph_id]
                    logger.trace(f"Creating new output/input pair to fallback graph: {arg}")
                    in_node = fallback_graph.placeholder(arg.name)
                    if not already_output:
                        scheduled_new_outputs.append((arg, in_node))
                    new_io_mapping[in_node] = arg
                    arg_map[arg] = in_node
                    continue

                if arg.op == "placeholder":
                    # We need to create a new placeholder in the fallback graph
                    logger.trace(f"Copying placeholder to fallback graph: {arg}")
                    in_node = fallback_graph.placeholder(arg.name)
                    arg_map[arg] = in_node
                    placeholder_map[in_node] = arg
                    continue

                # Explicitly allow other types for now, so that we don't miss anything important. Eventually we can remove the assert
                if arg.op in ["int", "float"]:
                    continue

                assert False, f"Unsupported argument type {arg.op} for node {arg}"
                

            logger.trace(f"Falling back unsupported op, or needed nop, to fallback graph: {node}")
            copied_node_mapping[node] = fallback_graph.node_copy(node, lambda x: arg_map[x])
            device_kwarg_to_cpu(copied_node_mapping[node])

        # Create new outputs
        # Graph can only have one output, so we need to append it to existing output
        for source, dest in scheduled_new_outputs:
            append_to_output(device_graph, source)

        # Create new inputs
        for dest, source, new_source in scheduled_new_inputs:
            with device_graph.inserting_before(dest):
                in_node = device_graph.placeholder(source.name)
                in_node.meta["tensor_meta"] = source.meta["tensor_meta"]
            source.replace_all_uses_with(in_node)
            new_io_mapping[in_node] = new_source
        
        # Remove outputs
        output_node = get_output_node(device_graph)
        assert output_node is not None

        for driving_node in moved_output_mapping:
            remove_output_index(output_node, output_node.args[0].index(driving_node))

        # Remove the unsupported ops from the original graph
        for node in reversed(device_graph.nodes):
            if node in unsupported_ops:
                device_graph.erase_node(node)
        
        # Reduce unused stuff
        reduce_graph(device_graph)

        # Move outputs to the end
        move_output_to_end(device_graph)
        move_output_to_end(fallback_graph)

        graph_lint(device_graph, "Device_graph_after_fallback")
        graph_lint(fallback_graph, "Merged_fallback")

        logger.trace("After fallback:")
        logger.trace("Device graph:")
        if self.log_trace:
            device_graph.print_tabular()
        logger.trace("Fallback graph:")
        if self.log_trace:
            fallback_graph.print_tabular()
        logger.trace("IO Mappings: ", new_io_mapping)

        # Break up device/fallback graphs into multiple graphs if there are any circular dependencies
        device_graphs, fallback_graphs = self.break_up_deadlocks(subgraph_id, device_graph, fallback_graph, new_io_mapping, placeholder_map, copied_node_mapping, moved_output_mapping)

        device_graph = None # Clear the original graph variable to avoid accidental use
        
        """
        print("After breakup:")
        for i, g in enumerate(device_graphs):
            print(f"Device graph {i}:")
            g.print_tabular()
        for i, g in enumerate(fallback_graphs):
            print(f"Fallback graph {i}:")
            g.print_tabular()
        """

        # Update output nodes
        for i, node in enumerate(self.output_nodes_per_subgraph[subgraph_id]):
            if node in moved_output_mapping:
                self.output_nodes_per_subgraph[subgraph_id][i] = moved_output_mapping[node]

        # Clear fallback graphs if there's only one empty one
        if len(fallback_graphs) == 1 and len(fallback_graphs[0].nodes) == 0:
            fallback_graphs = []
        
        [graph_lint(d, f"Device_{i}") for i, d in enumerate(device_graphs)]
        [graph_lint(f, f"Fallback_{i}") for i, f in enumerate(fallback_graphs)]
        
        # If any final device graph is constant, let's move it to the cpu
        device_graphs_to_remove = []
        for i, device_graph in enumerate(device_graphs):
            if len(device_graph.nodes) > 0 and (is_nop_graph(device_graph) or is_constant_graph(device_graph) or not has_output(device_graph)):
                logger.debug(f"Device graph {i} is a NOP or constant, moving to CPU")
                graph_to_device(device_graph, 'cpu')
                fallback_graphs.append(device_graph)
                device_graphs_to_remove.append(device_graph)
        
        for g in device_graphs_to_remove:
            device_graphs.remove(g)
                
        if len(device_graphs) == 0:
            device_graphs = [torch.fx.Graph()] # create a blank graph

        logger.trace("=== Final graphs:")
        logger.trace("= Device:")
        for i, g in enumerate(device_graphs):
            logger.trace(f"* Device graph {i}")
            if self.log_trace:
                g.print_tabular()
        logger.trace("= Fallbacks:")
        for i, f in enumerate(fallback_graphs):
            logger.trace(f"* Falllback graph {i}")
            if self.log_trace:
                f.print_tabular()

        self.fallback_graphs_per_subgraph[subgraph_id] = fallback_graphs
        self.mappings_per_subgraph[subgraph_id] = {
                "new_io_mapping": new_io_mapping,
                "placeholder_map": placeholder_map,
                "copied_node_mapping": copied_node_mapping,
                "moved_output_mapping": moved_output_mapping
        }
        self.device_graphs_per_subgraph[subgraph_id] = device_graphs

        return device_graphs

    def break_up_deadlocks(self, 
            subgraph_id: int,
            device_graph: torch.fx.Graph, 
            fallback_graph: torch.fx.Graph, 
            new_io_mapping: Dict[torch.fx.Node, torch.fx.Node],
            placeholder_map: Dict[torch.fx.Node, torch.fx.Node], 
            copied_node_mapping: Dict[torch.fx.Node, torch.fx.Node], 
            moved_output_mapping: Dict[torch.fx.Node, torch.fx.Node]) -> Tuple[List[torch.fx.Graph], List[torch.fx.Graph]]:

        # Search for any circular dependencies between graphs, and keep breaking them down into multiple graphs until
        # there are none left. 
        # Since the original graph should not legally have any circular dependencies, it should be possible to create
        # a set of smaller graphs without circular dependencies. 

        fallback_graphs = [fallback_graph] if len(fallback_graph.nodes) > 0 else []
        device_graphs = [device_graph] if len(device_graph.nodes) > 0 else []

        progress = True
        new_graphs = []

        # Put everything in working graphs, but keep track of which are fallback and which are device graphs above
        working_graphs = copy.copy(device_graphs) + copy.copy(fallback_graphs)

        # For each graph, figure out which graphs inputs are coming from, and which graph outputs are going to
        graph_inputs : Dict[torch.fx.Graph, Set[torch.fx.Node]] = defaultdict(set)
        graph_outputs : Dict[torch.fx.Graph, Set[torch.fx.Node]] = defaultdict(set)
        outputs_to_dest_node : Dict[torch.fx.Node, Set[torch.fx.Node]] = defaultdict(set) # map of output node to inputs in other graphs

        def calculate_dependencies(working_graphs: List[torch.fx.Graph]):
            # Recalculate from scratch. This is not efficient compared to doing it incrementally on every
            # graph change, but that would be error-prone... Let's optimize if it's really needed.
            graph_inputs.clear()
            outputs_to_dest_node.clear()

            for graph in working_graphs:
                for node in graph.nodes:
                    if node.op == 'placeholder':
                        graph_inputs[graph].add(node)

                    if node.op == 'output':
                        for arg in node.all_input_nodes:
                            # Figure out who needs this output
                            for k, v in new_io_mapping.items():
                                if v == arg:
                                    outputs_to_dest_node[arg].add(k)

            #print("Graph inputs:")
            #print(graph_inputs)
            #print("Graph outputs:")
            #print(graph_outputs)
            #print("Inputs to src graph:")
            #print(inputs_to_src_graph)
            #print("Outputs to dest graph:")
            #print(outputs_to_dest_graph)

        tracer = IOTracer(working_graphs)
        while progress:
            # Keep looking for input/output pair, make a copy of the graph and them remove down from input and up from output
            # If either/both graphs end up empty, then they are linked and we have a problem

            # There are probably better algorithms to do this :) - but this is simple and I think it works
            working_graphs.extend(new_graphs)
            calculate_dependencies(working_graphs)

            new_graphs = []
            progress = False
            dependency = None

            # For each input in each graph, trace to final output, or until we reach ourselves again, in which case we need to break the cycle
            for _, inputs in graph_inputs.items():
                for input_node in inputs:
                    output_node_for_cycle = tracer.trace_for_cycle(input_node, outputs_to_dest_node)
                    if output_node_for_cycle is not None:
                        progress = True
                        dependency = (output_node_for_cycle, input_node)
                        break

                if progress:
                    break

            if not progress:
                break
            
            assert dependency is not None
            assert dependency[0].graph == dependency[1].graph, "Dependency is not a loop"
            graph = dependency[0].graph
            
            starting_input, loopback_input = dependency

            # Create a copy, and separate graphs
            logger.debug(f"Graph has a dependency to break: {starting_input} -> {loopback_input}")
            graph.print_tabular()
            new_graph = torch.fx.Graph()
            #new_graph = copy.deepcopy(graph)
            copy_map = {}
            output_value = new_graph.graph_copy(graph, copy_map)
            new_output = new_graph.output(output_value)
            new_output.meta["tensor_meta"] = tuple(o.meta["tensor_meta"] for o in output_value)

            # Remove nodes from the original graph
            to_remove = []
            to_process = [starting_input]
            while to_process:
                node = to_process.pop()
                to_remove.append(node)
                for user in node.users:
                    if user not in to_remove:
                        if user.op == "output":
                            remove_output_index(user, user.args[0].index(node))
                            break # done at output
                        else:
                            to_process.append(user)
            
            for node in reversed(to_remove):
                graph.erase_node(node)

            reduce_graph(graph) # remove dead code
            assert len(graph.nodes) > 0, f"Graph {graph} is empty after trying to disjoin multiple fallback graphs"

            # Removed nodes from the copy
            to_remove = []
            to_process = [copy_map[loopback_input]]
            assert to_process[0].graph == new_graph
            
            while to_process:
                node = to_process.pop()
                to_remove.append(node)
                for user in node.users:
                    if user not in to_remove:
                        if user.op == "output":
                            remove_output_index(user, user.args[0].index(node))
                            break # done at output
                        else:
                            to_process.append(user)

            for node in reversed(to_remove):
                new_graph.erase_node(node)

            reduce_graph(new_graph)

            assert len(new_graph.nodes) > 0, f"Graph {new_graph} is empty after trying to disjoin multiple fallback graphs"

            new_graphs.append(new_graph)

            if graph in fallback_graphs:
                fallback_graphs.append(new_graph)
            else:
                device_graphs.append(new_graph)

            # Update mappings, as some nodes have moved into the new graph
            for node in new_graph.nodes:
                if node.op == "output":
                    continue
                    
                # Reverse lookup, since copy map is old->new, and we need new->old
                original_node = None
                for org_node, new_node in copy_map.items():
                    if new_node == node:
                        original_node = org_node
                        break
                assert original_node is not None

                for node_map in [new_io_mapping, placeholder_map, copied_node_mapping, moved_output_mapping]:
                    update_node_map(node_map, original_node, node)

                if original_node in self.output_nodes_per_subgraph[subgraph_id]:
                    self.output_nodes_per_subgraph[subgraph_id][self.output_nodes_per_subgraph[subgraph_id].index(original_node)] = node

            tracer.remove_graph(graph)
            tracer.add_graph(graph)
            tracer.add_graph(new_graph)

        return device_graphs, fallback_graphs


    def generate_schedule(self, subgraph_idx: int, aten_module: torch.fx.GraphModule) -> Schedule:
        # For given subgraph, figure out a schedule of FX and Buda graphs that need to run, and how to map inputs to outputs
        schedule = Schedule(
                self.input_nodes_per_subgraph[subgraph_idx], 
                self.output_nodes_per_subgraph[subgraph_idx], 
                aten_module,
                self.device_graphs_per_subgraph[subgraph_idx],
                self.fallback_graphs_per_subgraph[subgraph_idx], 
                self.mappings_per_subgraph[subgraph_idx])


        return schedule

def update_node_map(node_map: Dict[torch.fx.Node, torch.fx.Node], org_node: torch.fx.Node, new_node: torch.fx.Node):
    # Check both keys and values of the map for org_node and switch them to new_node
    if org_node in node_map:
        node_map[new_node] = node_map[org_node]
        del node_map[org_node]

    for k, v in node_map.items():
        if v == org_node:
            node_map[k] = new_node
            break

